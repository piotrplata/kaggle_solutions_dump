{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow, imsave #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add, SpatialDropout2D, Reshape\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.activations import elu\n",
    "from keras.layers import LeakyReLU, Dense\n",
    "from keras.layers import GlobalAveragePooling2D, Multiply, multiply, add\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import time\n",
    "t_start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet_resnet_v5.model\n",
      "Unet_resnet_v5.csv\n"
     ]
    }
   ],
   "source": [
    "version = 5\n",
    "basic_name = f'Unet_resnet_v{version}'\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b477613b6f7b4a2f89c01eca3b30d600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d27da0715e4d3b8faacbbd33d72b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reference  from Heng's discussion\n",
    "# https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/63984#382657\n",
    "def get_mask_type(mask):\n",
    "    border = 10\n",
    "    outer = np.zeros((101-2*border, 101-2*border), np.float32)\n",
    "    outer = cv2.copyMakeBorder(outer, border, border, border, border, borderType = cv2.BORDER_CONSTANT, value = 1)\n",
    "\n",
    "    cover = (mask>0.5).sum()\n",
    "    if cover < 8:\n",
    "        return 0 # empty\n",
    "    if cover == ((mask*outer) > 0.5).sum():\n",
    "        return 1 #border\n",
    "    if np.all(mask==mask[0]):\n",
    "        return 2 #vertical\n",
    "\n",
    "    percentage = cover/(101*101)\n",
    "    if percentage < 0.15:\n",
    "        return 3\n",
    "    elif percentage < 0.25:\n",
    "        return 4\n",
    "    elif percentage < 0.50:\n",
    "        return 5\n",
    "    elif percentage < 0.75:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "def histcoverage(coverage):\n",
    "    histall = np.zeros((1,8))\n",
    "    for c in coverage:\n",
    "        histall[0,c] += 1\n",
    "    return histall\n",
    "\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_target, 2)\n",
    "\n",
    "train_df[\"coverage_class\"] = train_df.masks.map(get_mask_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/.local/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Coverage class')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/.local/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Depth distribution')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the depth distributions\n",
    "\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state= 13372)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"softplus\")(x)\n",
    "    #x = LeakyReLU(alpha=0.3)(x)\n",
    "    #x = Lambda(lambda x :elu(x) + 1)(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False, squeeze_excite = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    if squeeze_excite:\n",
    "        x = scSE(x)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def cse_block(in_block, ch, ratio=16):\n",
    "    x = GlobalAveragePooling2D()(in_block)\n",
    "    x = Dense(ch//ratio)(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    return Multiply()([in_block, x])\n",
    "\n",
    "#channel squeeze, spatial excitation\n",
    "def sSE(input_features):\n",
    "    squeezed = Conv2D(1,kernel_size=(1,1),strides=(1,1),padding='same',activation=\"sigmoid\", use_bias=\"false\")(input_features)\n",
    "    excited = multiply([squeezed,input_features])\n",
    "    return excited\n",
    "\n",
    "#spatial squeeze, channel excitation\n",
    "def cSE(input_features, ratio = 2):\n",
    "    \n",
    "    filters = int(input_features.get_shape()[-1])\n",
    "    squeezed = GlobalAveragePooling2D()(input_features)\n",
    "    squeezed = Reshape((1,1,-1))(squeezed)\n",
    "    squeezed = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(squeezed)\n",
    "    squeezed = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(squeezed)\n",
    "    \n",
    "    excited = multiply([squeezed,input_features])\n",
    "    return excited\n",
    "\n",
    "#both \n",
    "def scSE(input_features, ratio = 2):\n",
    "    _cse = sSE(input_features)\n",
    "    _sse = cSE(input_features,ratio)\n",
    "    return add([_cse,_sse])\n",
    "\n",
    "def UpSampling2DBilinear(size):\n",
    "    return Lambda(lambda x: tf.image.resize_bilinear(x, size, align_corners=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True, False)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True,False)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True,False)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True,False)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(0)\n",
    "#             continue\n",
    "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n",
    "#             metric.append(1)\n",
    "#             continue\n",
    "        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 101, 101, 1)\n",
      "(800, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #append validation data\n",
    "# x_train = np.append(x_train, [np.fliplr(x) for x in x_valid], axis=0)\n",
    "# y_train = np.append(y_train, [np.fliplr(x) for x in y_valid], axis=0)\n",
    "\n",
    "# x_train = np.append(x_train,x_valid, axis=0)\n",
    "# y_train = np.append(y_train,y_valid, axis=0)\n",
    "# print(x_train.shape)\n",
    "# print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 101, 101, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 101, 101, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 101, 101, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 101, 101, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 101, 101, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 101, 101, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 101, 101, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 101, 101, 16) 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 101, 101, 16) 64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 101, 101, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 101, 101, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 101, 101, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 101, 101, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 101, 101, 16) 2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 101, 101, 16) 0           conv2d_5[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 101, 101, 16) 64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 101, 101, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 16)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 50, 50, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 50, 50, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50, 50, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 50, 50, 32)   9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 50, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 50, 50, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 50, 50, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 50, 50, 32)   0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 50, 32)   128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50, 50, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 50, 50, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 50, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 50, 50, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 50, 50, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 50, 50, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 50, 50, 32)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 50, 50, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 25, 25, 64)   0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 25, 25, 64)   0           conv2d_15[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 12, 12, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 12, 12, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 12, 12, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 12, 12, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 12, 12, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 12, 12, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 12, 128)  0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 12, 12, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 12, 12, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 12, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 12, 12, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 12, 12, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 12, 12, 128)  0           conv2d_20[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 12, 12, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 12, 12, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 6, 6, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 6, 6, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 6, 256)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 6, 6, 256)    590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 6, 6, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 6, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 6, 6, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 6, 256)    0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 6, 6, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 6, 256)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 6, 6, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 6, 6, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 6, 6, 256)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 6, 6, 256)    590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 6, 256)    0           conv2d_25[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 6, 6, 256)    1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 6, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 128)  295040      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12, 12, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 128)  295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 128)  147584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 12, 12, 128)  147584      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 12, 12, 128)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 12, 12, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 12, 12, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 128)  512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 128)  147584      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 64)     8192        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 1)    129         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1, 128)    8192        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 12, 12, 128)  0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 12, 12, 128)  0           dense_2[0][0]                    \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 12, 12, 128)  0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 12, 12, 128)  0           add_12[0][0]                     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 25, 25, 64)   73792       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 25, 25, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 25, 25, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 25, 25, 64)   73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 25, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 25, 25, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 25, 25, 64)   36928       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 25, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 25, 25, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 25, 25, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 25, 25, 64)   0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 25, 25, 64)   256         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 25, 25, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 25, 64)   36928       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 25, 25, 64)   256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 25, 25, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 25, 25, 64)   36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 1, 32)     2048        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 25, 25, 1)    65          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 1, 64)     2048        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 25, 25, 64)   0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 25, 25, 64)   0           dense_4[0][0]                    \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 25, 25, 64)   0           multiply_3[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 25, 25, 64)   0           add_15[0][0]                     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 25, 25, 64)   256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 25, 25, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 50, 50, 32)   18464       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 50, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 50, 50, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 50, 50, 32)   128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 50, 50, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 50, 50, 32)   9248        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 50, 50, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 50, 50, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 50, 50, 32)   9248        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 50, 50, 32)   0           conv2d_40[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 50, 50, 32)   128         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 50, 50, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 50, 50, 32)   9248        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 50, 50, 32)   128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 50, 50, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 50, 50, 32)   9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 32)           0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 1, 16)     512         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 50, 50, 1)    33          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1, 32)     512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 50, 50, 32)   0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 50, 50, 32)   0           dense_6[0][0]                    \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 50, 50, 32)   0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 50, 50, 32)   0           add_18[0][0]                     \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 50, 50, 32)   128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 50, 50, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 101, 101, 16) 4624        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 101, 101, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 101, 101, 32) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 101, 101, 16) 4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 101, 101, 16) 64          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 101, 101, 16) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 101, 101, 16) 2320        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 101, 101, 16) 64          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 101, 101, 16) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 101, 101, 16) 2320        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 101, 101, 16) 0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 101, 101, 16) 64          add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 101, 101, 16) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 101, 101, 16) 2320        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 101, 101, 16) 64          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 101, 101, 16) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 101, 101, 16) 2320        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 101, 101, 16) 0           conv2d_48[0][0]                  \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 101, 101, 16) 64          add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 101, 101, 16) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 101, 101, 1)  17          activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 101, 101, 1)  0           conv2d_49[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,141,588\n",
      "Trainable params: 5,134,228\n",
      "Non-trainable params: 7,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.25)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(#featurewise_center=True,\n",
    "                     #featurewise_std_normalization=True,\n",
    "                     #rotation_range=18,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.1,\n",
    "                     fill_mode='reflect',\n",
    "                     #shear_range = 12,\n",
    "                     \n",
    "                     )\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(x_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow(x_train,batch_size = 16,seed=seed)\n",
    "mask_generator = mask_datagen.flow(y_train,batch_size = 16,seed=seed)\n",
    "\n",
    "train_generator = zip(image_generator,mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 101, 101, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 101, 101, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 101, 101, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 101, 101, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 101, 101, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 101, 101, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 101, 101, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 101, 101, 16) 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 101, 101, 16) 64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 101, 101, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 101, 101, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 101, 101, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 101, 101, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 101, 101, 16) 2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 101, 101, 16) 0           conv2d_5[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 101, 101, 16) 64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 101, 101, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 16)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 50, 50, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 50, 50, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50, 50, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 50, 50, 32)   9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 50, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 50, 50, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 50, 50, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 50, 50, 32)   0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 50, 32)   128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50, 50, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 50, 50, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 50, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 50, 50, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 50, 50, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 50, 50, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 50, 50, 32)   128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 50, 50, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 25, 25, 64)   0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 25, 25, 64)   0           conv2d_15[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 12, 12, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 12, 12, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 12, 12, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 12, 12, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 12, 12, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 12, 12, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 12, 128)  0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 12, 12, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 12, 12, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 12, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 12, 12, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 12, 12, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 12, 12, 128)  0           conv2d_20[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 12, 12, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 12, 12, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 6, 6, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 6, 6, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 6, 256)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 6, 6, 256)    590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 6, 6, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 6, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 6, 6, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 6, 256)    0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 6, 6, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 6, 256)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 6, 6, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 6, 6, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 6, 6, 256)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 6, 6, 256)    590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 6, 256)    0           conv2d_25[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 6, 6, 256)    1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 6, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 128)  295040      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12, 12, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 128)  295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 128)  147584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 12, 12, 128)  147584      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 12, 12, 128)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 12, 12, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 12, 12, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 128)  512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 128)  147584      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 64)     8192        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 1)    129         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1, 128)    8192        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 12, 12, 128)  0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 12, 12, 128)  0           dense_2[0][0]                    \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 12, 12, 128)  0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 12, 12, 128)  0           add_12[0][0]                     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 25, 25, 64)   73792       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 25, 25, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 25, 25, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 25, 25, 64)   73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 25, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 25, 25, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 25, 25, 64)   36928       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 25, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 25, 25, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 25, 25, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 25, 25, 64)   0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 25, 25, 64)   256         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 25, 25, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 25, 64)   36928       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 25, 25, 64)   256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 25, 25, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 25, 25, 64)   36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 1, 32)     2048        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 25, 25, 1)    65          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 1, 64)     2048        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 25, 25, 64)   0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 25, 25, 64)   0           dense_4[0][0]                    \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 25, 25, 64)   0           multiply_3[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 25, 25, 64)   0           add_15[0][0]                     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 25, 25, 64)   256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 25, 25, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 50, 50, 32)   18464       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 50, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 50, 50, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 50, 50, 32)   128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 50, 50, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 50, 50, 32)   9248        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 50, 50, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 50, 50, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 50, 50, 32)   9248        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 50, 50, 32)   0           conv2d_40[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 50, 50, 32)   128         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 50, 50, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 50, 50, 32)   9248        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 50, 50, 32)   128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 50, 50, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 50, 50, 32)   9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 32)           0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 32)     0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 1, 16)     512         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 50, 50, 1)    33          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1, 32)     512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 50, 50, 32)   0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 50, 50, 32)   0           dense_6[0][0]                    \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 50, 50, 32)   0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 50, 50, 32)   0           add_18[0][0]                     \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 50, 50, 32)   128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 50, 50, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 101, 101, 16) 4624        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 101, 101, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 101, 101, 32) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 101, 101, 16) 4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 101, 101, 16) 64          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 101, 101, 16) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 101, 101, 16) 2320        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 101, 101, 16) 64          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 101, 101, 16) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 101, 101, 16) 2320        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 101, 101, 16) 0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 101, 101, 16) 64          add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 101, 101, 16) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 101, 101, 16) 2320        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 101, 101, 16) 64          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 101, 101, 16) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 101, 101, 16) 2320        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 101, 101, 16) 0           conv2d_48[0][0]                  \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 101, 101, 16) 64          add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 101, 101, 16) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 101, 101, 1)  17          activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 101, 101, 1)  0           conv2d_49[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,141,588\n",
      "Trainable params: 5,134,228\n",
      "Non-trainable params: 7,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from segmentation_models import Unet\n",
    "# c = optimizers.adam(lr = 0.01)\n",
    "# model1 = Unet(backbone_name='resnet34', encoder_weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 57s 9ms/step - loss: 0.5053 - my_iou_metric: 0.3452 - val_loss: 0.5062 - val_my_iou_metric: 0.3850\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.38500, saving model to Unet_resnet_v5.model\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 43s 7ms/step - loss: 0.3528 - my_iou_metric: 0.5054 - val_loss: 0.4122 - val_my_iou_metric: 0.3516\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.38500\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 43s 7ms/step - loss: 0.3031 - my_iou_metric: 0.5488 - val_loss: 0.3392 - val_my_iou_metric: 0.4977\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.38500 to 0.49775, saving model to Unet_resnet_v5.model\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 43s 7ms/step - loss: 0.2600 - my_iou_metric: 0.5729 - val_loss: 0.2326 - val_my_iou_metric: 0.6006\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.49775 to 0.60062, saving model to Unet_resnet_v5.model\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.2404 - my_iou_metric: 0.6008 - val_loss: 0.4746 - val_my_iou_metric: 0.5078\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.60062\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 43s 7ms/step - loss: 0.2206 - my_iou_metric: 0.6156 - val_loss: 0.2599 - val_my_iou_metric: 0.6199\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.60062 to 0.61987, saving model to Unet_resnet_v5.model\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.2150 - my_iou_metric: 0.6259 - val_loss: 0.3511 - val_my_iou_metric: 0.5837\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.61987\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.2010 - my_iou_metric: 0.6485 - val_loss: 0.1989 - val_my_iou_metric: 0.6493\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.61987 to 0.64925, saving model to Unet_resnet_v5.model\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1993 - my_iou_metric: 0.6496 - val_loss: 0.2008 - val_my_iou_metric: 0.6755\n",
      "\n",
      "Epoch 00009: val_my_iou_metric improved from 0.64925 to 0.67550, saving model to Unet_resnet_v5.model\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1953 - my_iou_metric: 0.6618 - val_loss: 0.2512 - val_my_iou_metric: 0.6019\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.67550\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1822 - my_iou_metric: 0.6664 - val_loss: 0.1909 - val_my_iou_metric: 0.6505\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.67550\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1775 - my_iou_metric: 0.6744 - val_loss: 0.2104 - val_my_iou_metric: 0.6403\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.67550\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1767 - my_iou_metric: 0.6785 - val_loss: 0.2084 - val_my_iou_metric: 0.6526\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.67550\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1654 - my_iou_metric: 0.6971 - val_loss: 0.1614 - val_my_iou_metric: 0.6444\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.67550\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1616 - my_iou_metric: 0.6937 - val_loss: 0.8556 - val_my_iou_metric: 0.4101\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.67550\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1563 - my_iou_metric: 0.7011 - val_loss: 0.1369 - val_my_iou_metric: 0.7304\n",
      "\n",
      "Epoch 00016: val_my_iou_metric improved from 0.67550 to 0.73038, saving model to Unet_resnet_v5.model\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1558 - my_iou_metric: 0.7086 - val_loss: 0.1416 - val_my_iou_metric: 0.7211\n",
      "\n",
      "Epoch 00017: val_my_iou_metric did not improve from 0.73038\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1461 - my_iou_metric: 0.7137 - val_loss: 0.2682 - val_my_iou_metric: 0.6750\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.73038\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1479 - my_iou_metric: 0.7116 - val_loss: 0.1400 - val_my_iou_metric: 0.7121\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve from 0.73038\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1414 - my_iou_metric: 0.7146 - val_loss: 0.1376 - val_my_iou_metric: 0.7309\n",
      "\n",
      "Epoch 00020: val_my_iou_metric improved from 0.73038 to 0.73088, saving model to Unet_resnet_v5.model\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1417 - my_iou_metric: 0.7199 - val_loss: 0.1479 - val_my_iou_metric: 0.7044\n",
      "\n",
      "Epoch 00021: val_my_iou_metric did not improve from 0.73088\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1377 - my_iou_metric: 0.7244 - val_loss: 0.1515 - val_my_iou_metric: 0.6981\n",
      "\n",
      "Epoch 00022: val_my_iou_metric did not improve from 0.73088\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1390 - my_iou_metric: 0.7236 - val_loss: 0.1448 - val_my_iou_metric: 0.7286\n",
      "\n",
      "Epoch 00023: val_my_iou_metric did not improve from 0.73088\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1359 - my_iou_metric: 0.7286 - val_loss: 0.1630 - val_my_iou_metric: 0.7169\n",
      "\n",
      "Epoch 00024: val_my_iou_metric did not improve from 0.73088\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1309 - my_iou_metric: 0.7216 - val_loss: 0.1961 - val_my_iou_metric: 0.7190\n",
      "\n",
      "Epoch 00025: val_my_iou_metric did not improve from 0.73088\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1274 - my_iou_metric: 0.7309 - val_loss: 0.1280 - val_my_iou_metric: 0.7456\n",
      "\n",
      "Epoch 00026: val_my_iou_metric improved from 0.73088 to 0.74563, saving model to Unet_resnet_v5.model\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1255 - my_iou_metric: 0.7318 - val_loss: 0.1360 - val_my_iou_metric: 0.7425\n",
      "\n",
      "Epoch 00027: val_my_iou_metric did not improve from 0.74563\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1201 - my_iou_metric: 0.7384 - val_loss: 0.1191 - val_my_iou_metric: 0.7449\n",
      "\n",
      "Epoch 00028: val_my_iou_metric did not improve from 0.74563\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1178 - my_iou_metric: 0.7400 - val_loss: 0.1302 - val_my_iou_metric: 0.7309\n",
      "\n",
      "Epoch 00029: val_my_iou_metric did not improve from 0.74563\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1246 - my_iou_metric: 0.7372 - val_loss: 0.1142 - val_my_iou_metric: 0.7520\n",
      "\n",
      "Epoch 00030: val_my_iou_metric improved from 0.74563 to 0.75200, saving model to Unet_resnet_v5.model\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1173 - my_iou_metric: 0.7419 - val_loss: 0.1260 - val_my_iou_metric: 0.7256\n",
      "\n",
      "Epoch 00031: val_my_iou_metric did not improve from 0.75200\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 45s 7ms/step - loss: 0.1140 - my_iou_metric: 0.7466 - val_loss: 0.1485 - val_my_iou_metric: 0.7441\n",
      "\n",
      "Epoch 00032: val_my_iou_metric did not improve from 0.75200\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 45s 7ms/step - loss: 0.1151 - my_iou_metric: 0.7482 - val_loss: 0.1337 - val_my_iou_metric: 0.7342\n",
      "\n",
      "Epoch 00033: val_my_iou_metric did not improve from 0.75200\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 45s 7ms/step - loss: 0.1108 - my_iou_metric: 0.7467 - val_loss: 0.1160 - val_my_iou_metric: 0.7414\n",
      "\n",
      "Epoch 00034: val_my_iou_metric did not improve from 0.75200\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1061 - my_iou_metric: 0.7484 - val_loss: 0.1292 - val_my_iou_metric: 0.7416\n",
      "\n",
      "Epoch 00035: val_my_iou_metric did not improve from 0.75200\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1086 - my_iou_metric: 0.7531 - val_loss: 0.1333 - val_my_iou_metric: 0.7234\n",
      "\n",
      "Epoch 00036: val_my_iou_metric did not improve from 0.75200\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.1038 - my_iou_metric: 0.7534 - val_loss: 0.1281 - val_my_iou_metric: 0.7535\n",
      "\n",
      "Epoch 00037: val_my_iou_metric improved from 0.75200 to 0.75350, saving model to Unet_resnet_v5.model\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0965 - my_iou_metric: 0.7560 - val_loss: 0.1409 - val_my_iou_metric: 0.7311\n",
      "\n",
      "Epoch 00038: val_my_iou_metric did not improve from 0.75350\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0951 - my_iou_metric: 0.7622 - val_loss: 0.1518 - val_my_iou_metric: 0.7396\n",
      "\n",
      "Epoch 00039: val_my_iou_metric did not improve from 0.75350\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 43s 7ms/step - loss: 0.0932 - my_iou_metric: 0.7636 - val_loss: 0.1548 - val_my_iou_metric: 0.7462\n",
      "\n",
      "Epoch 00040: val_my_iou_metric did not improve from 0.75350\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 43s 7ms/step - loss: 0.0949 - my_iou_metric: 0.7603 - val_loss: 0.1478 - val_my_iou_metric: 0.7190\n",
      "\n",
      "Epoch 00041: val_my_iou_metric did not improve from 0.75350\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0923 - my_iou_metric: 0.7697 - val_loss: 0.1245 - val_my_iou_metric: 0.7610\n",
      "\n",
      "Epoch 00042: val_my_iou_metric improved from 0.75350 to 0.76100, saving model to Unet_resnet_v5.model\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0919 - my_iou_metric: 0.7660 - val_loss: 0.1775 - val_my_iou_metric: 0.7180\n",
      "\n",
      "Epoch 00043: val_my_iou_metric did not improve from 0.76100\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0892 - my_iou_metric: 0.7683 - val_loss: 0.1411 - val_my_iou_metric: 0.7311\n",
      "\n",
      "Epoch 00044: val_my_iou_metric did not improve from 0.76100\n",
      "Epoch 45/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0860 - my_iou_metric: 0.7718 - val_loss: 0.1653 - val_my_iou_metric: 0.7215\n",
      "\n",
      "Epoch 00045: val_my_iou_metric did not improve from 0.76100\n",
      "Epoch 46/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0839 - my_iou_metric: 0.7735 - val_loss: 0.1596 - val_my_iou_metric: 0.7626\n",
      "\n",
      "Epoch 00046: val_my_iou_metric improved from 0.76100 to 0.76263, saving model to Unet_resnet_v5.model\n",
      "Epoch 47/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0831 - my_iou_metric: 0.7739 - val_loss: 0.1213 - val_my_iou_metric: 0.7606\n",
      "\n",
      "Epoch 00047: val_my_iou_metric did not improve from 0.76263\n",
      "Epoch 48/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0831 - my_iou_metric: 0.7780 - val_loss: 0.1410 - val_my_iou_metric: 0.7627\n",
      "\n",
      "Epoch 00048: val_my_iou_metric improved from 0.76263 to 0.76275, saving model to Unet_resnet_v5.model\n",
      "Epoch 49/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0846 - my_iou_metric: 0.7713 - val_loss: 0.1399 - val_my_iou_metric: 0.7489\n",
      "\n",
      "Epoch 00049: val_my_iou_metric did not improve from 0.76275\n",
      "Epoch 50/50\n",
      "6400/6400 [==============================] - 44s 7ms/step - loss: 0.0894 - my_iou_metric: 0.7721 - val_loss: 0.1173 - val_my_iou_metric: 0.7631\n",
      "\n",
      "Epoch 00050: val_my_iou_metric improved from 0.76275 to 0.76312, saving model to Unet_resnet_v5.model\n"
     ]
    }
   ],
   "source": [
    "#early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.8, patience=6, min_lr=0.001, verbose=1)\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "history = model1.fit(x_train, y_train,\n",
    "                     validation_data=[x_valid, y_valid], \n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     callbacks=[ model_checkpoint,reduce_lr], \n",
    "                     verbose=1)\n",
    "\n",
    "# history = model1.fit_generator(train_generator,\n",
    "#                      validation_data=[x_valid, y_valid], \n",
    "#                      epochs=epochs,\n",
    "#                      steps_per_epoch = 100,\n",
    "#                      callbacks=[ model_checkpoint,reduce_lr], \n",
    "#                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric,'elu':elu,'tf':tf})\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-+), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = optimizers.adam(lr = 0.05)\n",
    "\n",
    "# lovasz_loss need input range (-+), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lovasz_loss need input range (-+), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "#c = optimizers.adam(lr = 0.005)\n",
    "#model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/400\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: 0.6028 - my_iou_metric_2: 0.6737 - val_loss: 0.5335 - val_my_iou_metric_2: 0.7071\n",
      "\n",
      "Epoch 00001: val_my_iou_metric_2 improved from -inf to 0.70712, saving model to Unet_resnet_v5.model\n",
      "Epoch 2/400\n",
      "6400/6400 [==============================] - 95s 15ms/step - loss: 0.7076 - my_iou_metric_2: 0.6192 - val_loss: 0.9661 - val_my_iou_metric_2: 0.4963\n",
      "\n",
      "Epoch 00002: val_my_iou_metric_2 did not improve from 0.70712\n",
      "Epoch 3/400\n",
      "6400/6400 [==============================] - 95s 15ms/step - loss: 0.6051 - my_iou_metric_2: 0.6688 - val_loss: 0.5055 - val_my_iou_metric_2: 0.7135\n",
      "\n",
      "Epoch 00003: val_my_iou_metric_2 improved from 0.70712 to 0.71350, saving model to Unet_resnet_v5.model\n",
      "Epoch 4/400\n",
      "6400/6400 [==============================] - 94s 15ms/step - loss: 0.6207 - my_iou_metric_2: 0.6630 - val_loss: 0.5963 - val_my_iou_metric_2: 0.6759\n",
      "\n",
      "Epoch 00004: val_my_iou_metric_2 did not improve from 0.71350\n",
      "Epoch 5/400\n",
      "6400/6400 [==============================] - 94s 15ms/step - loss: 0.5811 - my_iou_metric_2: 0.6815 - val_loss: 0.5657 - val_my_iou_metric_2: 0.6965\n",
      "\n",
      "Epoch 00005: val_my_iou_metric_2 did not improve from 0.71350\n",
      "Epoch 6/400\n",
      "6400/6400 [==============================] - 94s 15ms/step - loss: 0.6717 - my_iou_metric_2: 0.6338 - val_loss: 21.8653 - val_my_iou_metric_2: 0.1713\n",
      "\n",
      "Epoch 00006: val_my_iou_metric_2 did not improve from 0.71350\n",
      "Epoch 7/400\n",
      "6400/6400 [==============================] - 94s 15ms/step - loss: 0.9902 - my_iou_metric_2: 0.3583 - val_loss: 1.0037 - val_my_iou_metric_2: 0.1890\n",
      "\n",
      "Epoch 00007: val_my_iou_metric_2 did not improve from 0.71350\n",
      "Epoch 8/400\n",
      "6400/6400 [==============================] - 95s 15ms/step - loss: 1.0067 - my_iou_metric_2: 0.3082 - val_loss: 1.0003 - val_my_iou_metric_2: 0.2368\n",
      "\n",
      "Epoch 00008: val_my_iou_metric_2 did not improve from 0.71350\n",
      "Epoch 9/400\n",
      "1472/6400 [=====>........................] - ETA: 1:07 - loss: 1.0056 - my_iou_metric_2: 0.3000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-eca226aa4175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=40, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.85, patience=7, min_lr=0.0005, verbose=1)\n",
    "epochs = 400\n",
    "batch_size = 16\n",
    "\n",
    "# history = model.fit_generator(train_generator,\n",
    "#                      validation_data=[x_valid, y_valid], \n",
    "#                      epochs=epochs,\n",
    "#                      steps_per_epoch = 600,\n",
    "#                      callbacks=[ model_checkpoint,reduce_lr], \n",
    "#                      verbose=1)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_loss.legend()\n",
    "ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n",
    "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n",
    "ax_score.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss,'tf':tf})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #freeze BN #compile after\n",
    "# for layer in model.layers:\n",
    "#     if type(layer) is BatchNormalization:\n",
    "#         layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8a7949b52d45a1bb6f5504171eb771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.824125 0.82575  0.829    0.8295   0.83     0.83075  0.8305   0.830875\n",
      " 0.831    0.831875 0.832    0.83225  0.83225  0.834125 0.83375  0.83575\n",
      " 0.837875 0.83775  0.838    0.83775  0.837875 0.8375   0.83725  0.836875\n",
      " 0.837    0.83675  0.8365   0.836375 0.837375 0.838125 0.83825 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9ef8a47a58>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original_image = Image which has to labelled\n",
    "#Mask image = Which has been labelled by some technique..\n",
    "def crf(original_image, mask_img):\n",
    "    \n",
    "    # Converting annotated image to RGB if it is Gray scale\n",
    "    if(len(mask_img.shape)<3):\n",
    "        mask_img = gray2rgb(mask_img)\n",
    "\n",
    "#     #Converting the annotations RGB color to single 32 bit integer\n",
    "    annotated_label = mask_img[:,:,0] + (mask_img[:,:,1]<<8) + (mask_img[:,:,2]<<16)\n",
    "    \n",
    "#     # Convert the 32bit integer color to 0,1, 2, ... labels.\n",
    "    colors, labels = np.unique(annotated_label, return_inverse=True)\n",
    "\n",
    "    n_labels = 2\n",
    "    \n",
    "    #Setting up the CRF model\n",
    "    d = dcrf.DenseCRF2D(original_image.shape[1], original_image.shape[0], n_labels)\n",
    "\n",
    "    # get unary potentials (neg log probability)\n",
    "    U = unary_from_labels(labels, n_labels, gt_prob=0.7, zero_unsure=False)\n",
    "    d.setUnaryEnergy(U)\n",
    "\n",
    "    # This adds the color-independent term, features are the locations only.\n",
    "    d.addPairwiseGaussian(sxy=(3, 3), compat=3, kernel=dcrf.DIAG_KERNEL,\n",
    "                      normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "        \n",
    "    #Run Inference for 10 steps \n",
    "    Q = d.inference(10)\n",
    "\n",
    "    # Find out the most probable class for each pixel.\n",
    "    MAP = np.argmax(Q, axis=0)\n",
    "\n",
    "    return MAP.reshape((original_image.shape[0],original_image.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3bc0870c9747df9b3da8865aad4286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([upsample(np.array(load_img(\"test/images/{}.png\".format(idx), grayscale=True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crf_masks_test = [crf(x_test[i],preds_test[i] > threshold_best) for i in tqdm_notebook(range(x_test.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c364ccf9e942dab0b971ced3715212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usedtime = 5.5192975997924805 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > 0.3)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel run time = 12.586112659176191 hours\n"
     ]
    }
   ],
   "source": [
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8472978603872034"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_best\n",
    "\n",
    "\n",
    "#with dropout 0.5 batchsize32 LB 0.810\n",
    "\n",
    "#changed model dropout to 0.25\n",
    "#changed batch size of seocnd training  to 16\n",
    "\n",
    "#threshold best -0.106\n",
    "#achieved LB 0.816\n",
    "#threshold -0.15 LB 0.816\n",
    "#threshold -0.3 LB 0.816\n",
    "#threshold -0.5 LB 0.814\n",
    "\n",
    "#removed dropout\n",
    "#finetuning last model with reflective padding data agumentation. <- good for overfitting\n",
    "#increase model size 4 times by increasing filters 2 time\n",
    "#increase batchszie to 40 (barchnorm?)\n",
    "#decrease to 16\n",
    "#add LeakyRelu\n",
    "\n",
    "#go back to 0.816 model but with leaky relu\n",
    "\n",
    "#\n",
    "#LR 9.000000427477062e-05\n",
    "#loss: 0.1735 - my_iou_metric_2: 0.8880 - val_loss: 0.3950 - val_my_iou_metric_2: 0.8235\n",
    "#sSE + hypercolumn\n",
    "#no agumentation\n",
    "#dropout 0, size 20\n",
    "#best lr 0.0003000000142492354.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove dropout\n",
    "#data agumentation? reflective padding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                      rle_mask\n",
       "id                                                           \n",
       "353e010b7b                                                   \n",
       "5439dbbddf                                                   \n",
       "71bab9f311                                                   \n",
       "52551f7a80                                                   \n",
       "512d8d9997  1620 1 1719 7 1819 9 1920 10 2021 11 2122 12 2...\n",
       "64dba827d6                                                   \n",
       "0a3a8a5f37                                                   \n",
       "329563756f  1 4039 4041 99 4142 99 4243 98 4344 98 4445 98...\n",
       "f6cba2e890  4132 6 4142 2 4229 12 4243 3 4325 18 4344 4 44...\n",
       "989c646373                                                   \n",
       "8ba0248e74                                                   \n",
       "d29d1424ce                                                   \n",
       "9834bd4034                                                   \n",
       "aa5f085ae7  96 6 197 6 298 6 400 5 502 4 604 3 707 1 2823 ...\n",
       "51caea4f7a  3128 4 3225 8 3323 11 3418 17 3516 20 3615 22 ...\n",
       "9a4d1749d4  77 25 178 25 279 25 381 24 482 24 583 24 684 2...\n",
       "5e52f098d9                                                   \n",
       "cc2b6a1eb2                                                   \n",
       "76784fa72d                                                   \n",
       "5b01231632  1 19 102 18 203 16 304 13 405 13 506 12 607 12...\n",
       "382b3f0c24                                                   \n",
       "e169daa2d7                   5689 17 5714 1 5769 84 5862 4340\n",
       "e9a6d47f94                                                   \n",
       "c2ec2c9de4                                                   \n",
       "b01d2e5375                                                   \n",
       "aebf30c3c7  1 6563 6566 98 6667 97 6768 95 6869 93 6977 83...\n",
       "63e0650693  1 24 102 23 203 22 304 21 405 20 506 19 607 18...\n",
       "60969ee8a0                                                   \n",
       "3e95d4417b  2713 14 2811 18 2911 19 3010 21 3105 27 3203 3...\n",
       "21006cd47c  55 47 157 46 259 45 362 43 465 41 568 39 672 3...\n",
       "...                                                       ...\n",
       "5a8b4aeb28  6667 12 6768 22 6869 29 6970 40 7071 47 7172 5...\n",
       "c8a0a0c511  606 1 705 3 805 4 906 4 1006 5 1107 5 1207 6 1...\n",
       "52889bff06  30 72 132 71 239 65 344 61 450 56 555 52 662 4...\n",
       "7f76751c6b  67 35 168 35 269 35 369 30 469 25 569 24 669 2...\n",
       "47c58dfdae                                                   \n",
       "d155b45b62  1 6866 6869 97 6970 93 7071 91 7172 88 7273 87...\n",
       "82b62ee3be  33 44 135 43 236 43 337 43 437 44 538 44 639 4...\n",
       "16da227a77                                                   \n",
       "d7de9e7fd6  4 98 106 97 208 96 313 92 418 88 522 85 626 82...\n",
       "228c4daacd  37 65 138 65 239 65 339 66 439 67 538 69 638 7...\n",
       "ab89a9e4e5  1208 5 1306 8 1405 10 1503 13 1602 15 1702 16 ...\n",
       "bce80dc1da  66 36 167 36 267 37 367 38 467 39 567 40 667 4...\n",
       "c229e55bfa                                                   \n",
       "fb9a1efb51  1 6863 6869 89 6970 84 7071 78 7172 73 7273 70...\n",
       "a7d56ddaf1  1 42 102 42 203 42 304 43 405 43 506 44 607 44...\n",
       "b35a524585                                                   \n",
       "ffdc97aa4f  49 53 151 52 253 51 355 50 457 49 559 48 661 4...\n",
       "840edfd9b0                                                   \n",
       "c9d1f1d210                                                   \n",
       "fea5f19d76                                                   \n",
       "3dd0afef2c                                                   \n",
       "838e2cfbb1  1 2828 2830 100 2932 99 3034 98 3136 97 3239 9...\n",
       "b387191390                                                   \n",
       "f33ac8fba7  1 4061 4069 94 4175 68 4244 18 4280 24 4309 7 ...\n",
       "9f7f3b3c88  5515 6 5610 16 5707 28 5750 7 5805 54 5874 3 5...\n",
       "09f1675cfb  1011 1 1112 5 1213 10 1314 14 1415 17 1516 21 ...\n",
       "6947dbc4f4                                                   \n",
       "68de95fb39  1 83 102 83 203 83 304 82 405 82 506 82 607 83...\n",
       "fdad2f99d8                                                   \n",
       "d7c57f676e  8773 15 8869 20 8965 25 9058 33 9154 38 9250 4...\n",
       "\n",
       "[18000 rows x 1 columns]>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO maybe excitation, maybe spatial dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
